{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Networks with minpy+mxnet\n",
    "\n",
    "In this notebook, we show how to implement a CNN with minpy and mxnet. Your job is to design the forward model and train the parameters. Note that the convolution layers are efficiently implemented by using mxnet symbols. You should get more than 70% accuracy on validation dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Iteration 1 / 1914) loss: 2.334938\n",
      "(Iteration 41 / 1914) loss: 2.195728\n",
      "(Iteration 81 / 1914) loss: 2.061162\n",
      "(Iteration 121 / 1914) loss: 1.992989\n",
      "(Iteration 161 / 1914) loss: 1.899949\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8ce8ec78aa19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Train!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/nn/solver.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0meach_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# Maybe print training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/nn/solver.pyc\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    174\u001b[0m         grad_and_loss_func = core.grad_and_loss(\n\u001b[1;32m    175\u001b[0m             loss_func, argnum=range(len(param_arrays)))\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mgrad_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_and_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparam_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/core.pyc\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Forward pass finished. Start backward pass.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mcurrent_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_gradient_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mgrad_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcurrent_tape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_vals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mgrad_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/tape.pyc\u001b[0m in \u001b[0;36mget_gradient\u001b[0;34m(self, origin)\u001b[0m\n\u001b[1;32m    165\u001b[0m                     _logger.debug(\n\u001b[1;32m    166\u001b[0m                         'Calling derivative func \"{}\"'.format(grad_record.grad_func))\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cached_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cumulate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/primitive.pyc\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_mxnet_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/primitive.pyc\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(result)\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/minpy/array_variants/mxnet/mxnet_core.pyc\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xu/mxnet/python/mxnet/ndarray.pyc\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/xu/mxnet/python/mxnet/ndarray.pyc\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''This is for cs231 assignment2, a convolutional neural network using Minpy and Mxnet'''\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "import minpy\n",
    "import minpy.numpy as np\n",
    "import mxnet as mx\n",
    "from minpy.nn.io import NDArrayIter\n",
    "# Can also use MXNet IO here\n",
    "# from mxnet.io import NDArrayIter\n",
    "from minpy.core import Function\n",
    "from minpy.nn import layers\n",
    "from minpy.nn.model import ModelBase\n",
    "from minpy.nn.solver import Solver\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "\n",
    "# Please uncomment following if you have GPU-enabled MXNet installed.\n",
    "#from minpy.context import set_context, gpu\n",
    "#set_context(gpu(0)) # set the global context as gpu(0)\n",
    "\n",
    "batch_size=128\n",
    "input_size=(3, 32, 32)\n",
    "flattened_input_size=3 * 32 * 32\n",
    "hidden_size=64\n",
    "num_classes=10\n",
    "reg = 0.001\n",
    "nfilter = 16\n",
    "ks = (3,3)\n",
    "nepo = 5\n",
    "learning_rate = 2e-4\n",
    "\n",
    "\n",
    "class ConvolutionNet(ModelBase):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionNet, self).__init__()\n",
    "        # Define your cnn below.\n",
    "        net = mx.sym.Variable(name='X')\n",
    "        \n",
    "        net = mx.sym.Convolution(\n",
    "                data=net, name='conv1', kernel=ks, num_filter=nfilter)\n",
    "        net = mx.symbol.BatchNorm(data=net, name='bn1')\n",
    "        net = mx.sym.Activation(\n",
    "                data=net, act_type='relu')\n",
    "        net = mx.sym.Pooling(\n",
    "                data=net, name='pool1', pool_type='max', kernel=(2, 2),\n",
    "                stride=(2, 2))\n",
    "        net = mx.sym.Convolution(\n",
    "                data=net, name='conv2', kernel=ks, num_filter=nfilter)\n",
    "        net = mx.symbol.BatchNorm(data=net, name='bn2')\n",
    "        net = mx.sym.Activation(\n",
    "                data=net, act_type='relu')\n",
    "        net = mx.sym.Pooling(\n",
    "                data=net, name='pool2', pool_type='max', kernel=(2, 2),\n",
    "                stride=(2, 2))\n",
    "        net = mx.sym.Flatten(data=net)\n",
    "        \n",
    "        # Create forward function and add parameters to this model.\n",
    "        self.conv = Function(\n",
    "                net, input_shapes={'X': (batch_size,) + input_size},\n",
    "                name='conv')\n",
    "        self.add_params(self.conv.get_params())\n",
    "        \n",
    "        # Define ndarray parameters used for fully connected and bn layers.\n",
    "        output_shape = self.conv.get_one_output_shape()\n",
    "        conv_out_size = output_shape[1]\n",
    "        self.add_param(name='w1', shape=(conv_out_size, hidden_size)) \\\n",
    "            .add_param(name='b1', shape=(hidden_size,)) \\\n",
    "            .add_param(name='w2', shape=(hidden_size, num_classes)) \\\n",
    "            .add_param(name='b2', shape=(num_classes,))\\\n",
    "            .add_aux_param(name='running_mean', value=None) \\\n",
    "            .add_aux_param(name='running_var', value=None)\\\n",
    "            .add_param(name='gamma1', shape=(hidden_size,), init_rule='constant', init_config={'value': 1.0}) \\\n",
    "            .add_param(name='beta1', shape=(hidden_size,), init_rule='constant') \n",
    "\n",
    "    def forward(self, X, mode):\n",
    "        out = self.conv(X=X, **self.params)\n",
    "        out = layers.affine(out, self.params['w1'], self.params['b1'])\n",
    "       \n",
    "        # add a BN layer into fully conneted layers\n",
    "        out, self.aux_params['running_mean'], self.aux_params['running_var'] = layers.batchnorm(\\\n",
    "            out, self.params['gamma1'], self.params['beta1'], running_mean=self.aux_params['running_mean'],\\\n",
    "            running_var=self.aux_params['running_var'])\n",
    "       \n",
    "        out = layers.relu(out)\n",
    "        out = layers.affine(out, self.params['w2'], self.params['b2'])\n",
    "        return out\n",
    "\n",
    "    def loss(self, predict, y):\n",
    "        loss_reg = 0\n",
    "        for name, weight in self.params.iteritems():\n",
    "            loss_reg += np.sum(weight**2)\n",
    "        return layers.softmax_loss(predict, y) + loss_reg*reg*0.5\n",
    "\n",
    "# Create model.\n",
    "model = ConvolutionNet()\n",
    "# Create data iterators for training and testing sets.\n",
    "data = get_CIFAR10_data()\n",
    "train_dataiter = NDArrayIter(data=data['X_train'],\n",
    "                             label=data['y_train'],\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True)\n",
    "test_dataiter = NDArrayIter(data=data['X_test'],\n",
    "                            label=data['y_test'],\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "# Create solver.\n",
    "solver = Solver(model,\n",
    "                train_dataiter,\n",
    "                test_dataiter,\n",
    "                num_epochs=nepo,\n",
    "                init_rule='gaussian',\n",
    "                init_config={\n",
    "                    'stdvar': 0.001\n",
    "                },\n",
    "                #update_rule='sgd_momentum',\n",
    "            #update_rule='rmsprop',\n",
    "                update_rule ='adam',\n",
    "                optim_config={\n",
    "                    'learning_rate': learning_rate\n",
    "                },\n",
    "                verbose=True,\n",
    "                print_every=40)\n",
    "# Initialize model parameters.\n",
    "solver.init()\n",
    "# Train!\n",
    "solver.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
